{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LuUnLztiY_P","executionInfo":{"status":"ok","timestamp":1664884324422,"user_tz":-480,"elapsed":3059,"user":{"displayName":"段宥任","userId":"13882398319127726760"}},"outputId":"99659957-d32a-4caa-915e-dc991a06a0bc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-yccrr1REiD","executionInfo":{"status":"ok","timestamp":1664884325895,"user_tz":-480,"elapsed":1479,"user":{"displayName":"段宥任","userId":"13882398319127726760"}},"outputId":"c0a03c29-b983-414b-b36f-296ab2afbfc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 16322 images belonging to 101 classes.\n","Found 4049 images belonging to 101 classes.\n"]}],"source":["from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","train_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,\n","    #rotation_range=40,\n","    #width_shift_range=0.2,\n","    #height_shift_range=0.2,\n","    #shear_range=0.2,\n","    #zoom_range=0.2,\n","    #channel_shift_range=10,\n","    #horizontal_flip=True,\n","    #vertical_flip=True,\n","    #fill_mode='nearest',\n","    validation_split=0.2,\n","    rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    directory='/content/drive/MyDrive/AI_共用/AI_辨識食物類別/tw_food_101',\n","    target_size=(200,200),\n","    batch_size=16,\n","    subset='training')\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    directory='/content/drive/MyDrive/AI_共用/AI_辨識食物類別/tw_food_101',\n","    target_size=(200,200),\n","    batch_size=16,\n","    subset='validation')"]},{"cell_type":"code","source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import load_img\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","resnet_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(200, 200, 3))"],"metadata":{"id":"QNyhZDgJR3ny","executionInfo":{"status":"ok","timestamp":1664884326913,"user_tz":-480,"elapsed":1021,"user":{"displayName":"段宥任","userId":"13882398319127726760"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#X_train = preprocess_input(train_generator)"],"metadata":{"id":"yz9dxQAyWIfu","executionInfo":{"status":"ok","timestamp":1664884326914,"user_tz":-480,"elapsed":3,"user":{"displayName":"段宥任","userId":"13882398319127726760"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(resnet_model)\n","model.add(Dropout(0.5))\n","model.add(GlobalAveragePooling2D())\n","#model.add(Dense(50))\n","model.add(Dropout(0.5))\n","model.add(Dense(101, activation=\"softmax\"))\n","model.summary()   # 顯示模型摘要資訊\n","\n","resnet_model.trainable = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOoBGi30WG7R","executionInfo":{"status":"ok","timestamp":1664884327289,"user_tz":-480,"elapsed":378,"user":{"displayName":"段宥任","userId":"13882398319127726760"}},"outputId":"17ebcafc-e056-48cb-ef6d-51aea2db2565"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n","                                                                 \n"," dropout_2 (Dropout)         (None, 7, 7, 2048)        0         \n","                                                                 \n"," global_average_pooling2d_1   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dropout_3 (Dropout)         (None, 2048)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 101)               206949    \n","                                                                 \n","=================================================================\n","Total params: 23,794,661\n","Trainable params: 23,741,541\n","Non-trainable params: 53,120\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"],"metadata":{"id":"KQvI2WTnXIZM","executionInfo":{"status":"ok","timestamp":1664884327291,"user_tz":-480,"elapsed":5,"user":{"displayName":"段宥任","userId":"13882398319127726760"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["es = EarlyStopping(monitor = \"accuracy\", mode = \"auto\", patience = 3, verbose = 1)\n","mc = ModelCheckpoint(\"/content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\", monitor=\"accuracy\", mode=\"auto\", verbose=1,\n","                     save_best_only=True)"],"metadata":{"id":"WUtl2ZYMXJgq","executionInfo":{"status":"ok","timestamp":1664884327291,"user_tz":-480,"elapsed":4,"user":{"displayName":"段宥任","userId":"13882398319127726760"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import time\n","time_start = time.time() #開始計時"],"metadata":{"id":"nRPkgo4PXRzj","executionInfo":{"status":"ok","timestamp":1664884327292,"user_tz":-480,"elapsed":5,"user":{"displayName":"段宥任","userId":"13882398319127726760"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["history = model.fit_generator(\n","    train_generator,\n","    epochs=50,\n","    validation_data = validation_generator,\n","    callbacks = [es, mc])"],"metadata":{"id":"EBmZmX6KXTG3","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1664902557692,"user_tz":-480,"elapsed":18230405,"user":{"displayName":"段宥任","userId":"13882398319127726760"}},"outputId":"a73497c1-9d47-4816-9ff0-d98909016b07"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \"\"\"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","  34/1021 [..............................] - ETA: 1:30:01 - loss: 5.3300 - accuracy: 0.0037"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3004 bytes but only got 0. Skipping tag 37500\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41486\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41487\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"]},{"output_type":"stream","name":"stdout","text":[" 137/1021 [===>..........................] - ETA: 1:20:19 - loss: 5.0903 - accuracy: 0.0137"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 256 bytes but only got 230. Skipping tag 50341\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"]},{"output_type":"stream","name":"stdout","text":[" 748/1021 [====================>.........] - ETA: 25:31 - loss: 4.9110 - accuracy: 0.0115"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["1021/1021 [==============================] - ETA: 0s - loss: 4.8761 - accuracy: 0.0126\n","Epoch 1: accuracy improved from -inf to 0.01262, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 7280s 7s/step - loss: 4.8761 - accuracy: 0.0126 - val_loss: 4.6381 - val_accuracy: 0.0203\n","Epoch 2/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.7133 - accuracy: 0.0206\n","Epoch 2: accuracy improved from 0.01262 to 0.02059, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 341s 334ms/step - loss: 4.7133 - accuracy: 0.0206 - val_loss: 4.5699 - val_accuracy: 0.0232\n","Epoch 3/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.6734 - accuracy: 0.0204\n","Epoch 3: accuracy did not improve from 0.02059\n","1021/1021 [==============================] - 326s 319ms/step - loss: 4.6734 - accuracy: 0.0204 - val_loss: 4.5577 - val_accuracy: 0.0301\n","Epoch 4/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.6314 - accuracy: 0.0245\n","Epoch 4: accuracy improved from 0.02059 to 0.02451, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 318s 311ms/step - loss: 4.6314 - accuracy: 0.0245 - val_loss: 4.4927 - val_accuracy: 0.0314\n","Epoch 5/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.6009 - accuracy: 0.0281\n","Epoch 5: accuracy improved from 0.02451 to 0.02806, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 316s 309ms/step - loss: 4.6009 - accuracy: 0.0281 - val_loss: 4.4765 - val_accuracy: 0.0393\n","Epoch 6/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5864 - accuracy: 0.0278\n","Epoch 6: accuracy did not improve from 0.02806\n","1021/1021 [==============================] - 314s 307ms/step - loss: 4.5864 - accuracy: 0.0278 - val_loss: 4.4558 - val_accuracy: 0.0425\n","Epoch 7/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5633 - accuracy: 0.0320\n","Epoch 7: accuracy improved from 0.02806 to 0.03204, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 314s 307ms/step - loss: 4.5633 - accuracy: 0.0320 - val_loss: 4.4328 - val_accuracy: 0.0351\n","Epoch 8/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5481 - accuracy: 0.0332\n","Epoch 8: accuracy improved from 0.03204 to 0.03321, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 314s 308ms/step - loss: 4.5481 - accuracy: 0.0332 - val_loss: 4.4299 - val_accuracy: 0.0294\n","Epoch 9/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5456 - accuracy: 0.0335\n","Epoch 9: accuracy improved from 0.03321 to 0.03351, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 315s 309ms/step - loss: 4.5456 - accuracy: 0.0335 - val_loss: 4.4052 - val_accuracy: 0.0274\n","Epoch 10/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5242 - accuracy: 0.0359\n","Epoch 10: accuracy improved from 0.03351 to 0.03590, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 313s 307ms/step - loss: 4.5242 - accuracy: 0.0359 - val_loss: 4.4312 - val_accuracy: 0.0316\n","Epoch 11/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5061 - accuracy: 0.0377\n","Epoch 11: accuracy improved from 0.03590 to 0.03768, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 315s 308ms/step - loss: 4.5061 - accuracy: 0.0377 - val_loss: 4.4004 - val_accuracy: 0.0403\n","Epoch 12/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.5012 - accuracy: 0.0354\n","Epoch 12: accuracy did not improve from 0.03768\n","1021/1021 [==============================] - 315s 308ms/step - loss: 4.5012 - accuracy: 0.0354 - val_loss: 4.3942 - val_accuracy: 0.0482\n","Epoch 13/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4924 - accuracy: 0.0406\n","Epoch 13: accuracy improved from 0.03768 to 0.04062, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 315s 308ms/step - loss: 4.4924 - accuracy: 0.0406 - val_loss: 4.3907 - val_accuracy: 0.0435\n","Epoch 14/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4831 - accuracy: 0.0398\n","Epoch 14: accuracy did not improve from 0.04062\n","1021/1021 [==============================] - 313s 306ms/step - loss: 4.4831 - accuracy: 0.0398 - val_loss: 4.3577 - val_accuracy: 0.0521\n","Epoch 15/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4789 - accuracy: 0.0431\n","Epoch 15: accuracy improved from 0.04062 to 0.04313, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 311s 305ms/step - loss: 4.4789 - accuracy: 0.0431 - val_loss: 4.3791 - val_accuracy: 0.0400\n","Epoch 16/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4628 - accuracy: 0.0422\n","Epoch 16: accuracy did not improve from 0.04313\n","1021/1021 [==============================] - 310s 304ms/step - loss: 4.4628 - accuracy: 0.0422 - val_loss: 4.3465 - val_accuracy: 0.0514\n","Epoch 17/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4669 - accuracy: 0.0435\n","Epoch 17: accuracy improved from 0.04313 to 0.04350, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 322s 316ms/step - loss: 4.4669 - accuracy: 0.0435 - val_loss: 4.3015 - val_accuracy: 0.0625\n","Epoch 18/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4410 - accuracy: 0.0449\n","Epoch 18: accuracy improved from 0.04350 to 0.04491, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 324s 317ms/step - loss: 4.4410 - accuracy: 0.0449 - val_loss: 4.3583 - val_accuracy: 0.0393\n","Epoch 19/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4493 - accuracy: 0.0422\n","Epoch 19: accuracy did not improve from 0.04491\n","1021/1021 [==============================] - 328s 321ms/step - loss: 4.4493 - accuracy: 0.0422 - val_loss: 4.3211 - val_accuracy: 0.0541\n","Epoch 20/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4332 - accuracy: 0.0458\n","Epoch 20: accuracy improved from 0.04491 to 0.04577, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 342s 335ms/step - loss: 4.4332 - accuracy: 0.0458 - val_loss: 4.3600 - val_accuracy: 0.0462\n","Epoch 21/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4400 - accuracy: 0.0453\n","Epoch 21: accuracy did not improve from 0.04577\n","1021/1021 [==============================] - 312s 306ms/step - loss: 4.4400 - accuracy: 0.0453 - val_loss: 4.3230 - val_accuracy: 0.0504\n","Epoch 22/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4266 - accuracy: 0.0453\n","Epoch 22: accuracy did not improve from 0.04577\n","1021/1021 [==============================] - 317s 311ms/step - loss: 4.4266 - accuracy: 0.0453 - val_loss: 4.3435 - val_accuracy: 0.0519\n","Epoch 23/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4251 - accuracy: 0.0467\n","Epoch 23: accuracy improved from 0.04577 to 0.04669, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 327s 320ms/step - loss: 4.4251 - accuracy: 0.0467 - val_loss: 4.3575 - val_accuracy: 0.0375\n","Epoch 24/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4095 - accuracy: 0.0463\n","Epoch 24: accuracy did not improve from 0.04669\n","1021/1021 [==============================] - 323s 316ms/step - loss: 4.4095 - accuracy: 0.0463 - val_loss: 4.3185 - val_accuracy: 0.0551\n","Epoch 25/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4142 - accuracy: 0.0483\n","Epoch 25: accuracy improved from 0.04669 to 0.04828, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 315s 309ms/step - loss: 4.4142 - accuracy: 0.0483 - val_loss: 4.3214 - val_accuracy: 0.0501\n","Epoch 26/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4074 - accuracy: 0.0497\n","Epoch 26: accuracy improved from 0.04828 to 0.04969, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 318s 311ms/step - loss: 4.4074 - accuracy: 0.0497 - val_loss: 4.3214 - val_accuracy: 0.0575\n","Epoch 27/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4020 - accuracy: 0.0509\n","Epoch 27: accuracy improved from 0.04969 to 0.05085, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 316s 310ms/step - loss: 4.4020 - accuracy: 0.0509 - val_loss: 4.3615 - val_accuracy: 0.0422\n","Epoch 28/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.4048 - accuracy: 0.0490\n","Epoch 28: accuracy did not improve from 0.05085\n","1021/1021 [==============================] - 317s 311ms/step - loss: 4.4048 - accuracy: 0.0490 - val_loss: 4.3145 - val_accuracy: 0.0529\n","Epoch 29/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.3817 - accuracy: 0.0512\n","Epoch 29: accuracy improved from 0.05085 to 0.05122, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 320s 314ms/step - loss: 4.3817 - accuracy: 0.0512 - val_loss: 4.3721 - val_accuracy: 0.0529\n","Epoch 30/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.3718 - accuracy: 0.0539\n","Epoch 30: accuracy improved from 0.05122 to 0.05385, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 321s 314ms/step - loss: 4.3718 - accuracy: 0.0539 - val_loss: 4.3175 - val_accuracy: 0.0635\n","Epoch 31/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.3852 - accuracy: 0.0507\n","Epoch 31: accuracy did not improve from 0.05385\n","1021/1021 [==============================] - 320s 314ms/step - loss: 4.3852 - accuracy: 0.0507 - val_loss: 4.3407 - val_accuracy: 0.0531\n","Epoch 32/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.3746 - accuracy: 0.0501\n","Epoch 32: accuracy did not improve from 0.05385\n","1021/1021 [==============================] - 322s 315ms/step - loss: 4.3746 - accuracy: 0.0501 - val_loss: 4.3134 - val_accuracy: 0.0509\n","Epoch 33/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.3712 - accuracy: 0.0540\n","Epoch 33: accuracy improved from 0.05385 to 0.05398, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 323s 316ms/step - loss: 4.3712 - accuracy: 0.0540 - val_loss: 4.3194 - val_accuracy: 0.0590\n","Epoch 34/50\n","1021/1021 [==============================] - ETA: 0s - loss: 4.3688 - accuracy: 0.0547\n","Epoch 34: accuracy improved from 0.05398 to 0.05471, saving model to /content/drive/MyDrive/AI_共用/AI_辨識食物類別/best_model.h5\n","1021/1021 [==============================] - 322s 316ms/step - loss: 4.3688 - accuracy: 0.0547 - val_loss: 4.2756 - val_accuracy: 0.0585\n","Epoch 35/50\n"," 956/1021 [===========================>..] - ETA: 16s - loss: 4.3718 - accuracy: 0.0527"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-d37c0144e6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     callbacks = [es, mc])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["time_end = time.time()    #結束計時\n","\n","time_c= time_end - time_start   #執行所花時間\n","print('time cost', time_c, 's')"],"metadata":{"id":"VIuPuG_sXU7W","executionInfo":{"status":"aborted","timestamp":1664902557694,"user_tz":-480,"elapsed":12,"user":{"displayName":"段宥任","userId":"13882398319127726760"}}},"execution_count":null,"outputs":[]}]}